// index.js â€” Render (Server)
// --------------------------------------------
import express from "express";
import http from "http";
import { Server } from "socket.io";
import OpenAI from "openai";
import dotenv from "dotenv";

dotenv.config();

const app = express();
const server = http.createServer(app);
const io = new Server(server, {
  cors: {
    origin: ["https://translate-app-topaz.vercel.app"],
    methods: ["GET", "POST"]
  },
  transports: ["websocket"], // âœ… WebSocketå›ºå®šï¼ˆpollingç„¡åŠ¹ï¼‰
});

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

app.use(express.static("public"));

const PORT = process.env.PORT || 10000;

// ğŸ”¸ å„ãƒ«ãƒ¼ãƒ ã”ã¨ã®ãƒ­ã‚°ä¿å­˜ï¼ˆæœ€å¤§50ä»¶ï¼‰
const roomLogs = {};

// ğŸ”¹ ãƒ¢ãƒ¼ãƒ‰ï¼ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ï¼ˆå…¨ä½“å…±æœ‰ï¼‰
let currentMode = "æ„è¨³";
let currentModel = "gpt-4o"; // ç²¾åº¦é‡è¦–ãŒåˆæœŸå€¤

// --------------------------------------------
// ğŸ”¸ ã‚½ã‚±ãƒƒãƒˆé€šä¿¡è¨­å®š
// --------------------------------------------
io.on("connection", (socket) => {
  console.log("âœ… Connected:", socket.id);

  socket.on("joinRoom", (roomId) => {
    socket.join(roomId);
    if (!roomLogs[roomId]) roomLogs[roomId] = [];

    // å‚åŠ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ãƒ­ã‚°ã¨è¨­å®šã‚’é€ä¿¡
    socket.emit("initRoom", {
      logs: roomLogs[roomId],
      mode: currentMode,
      model: currentModel
    });
  });

  // å…¥åŠ›å†…å®¹ã‚’åŒæœŸ
  socket.on("inputUpdate", ({ roomId, uid, text }) => {
    socket.to(roomId).emit("inputSync", { uid, text });
  });

  // ãƒ¢ãƒ¼ãƒ‰æ›´æ–°
  socket.on("updateMode", (mode) => {
    currentMode = mode;
    io.emit("modeUpdated", mode);
  });

  // ãƒ¢ãƒ‡ãƒ«æ›´æ–°
  socket.on("updateModel", (model) => {
    currentModel = model;
    io.emit("modelUpdated", model);
  });

  // ğŸ”¸ ç¿»è¨³å‡¦ç†
  socket.on("translate", async ({ roomId, uid, inputText, inputLang, outputLang }) => {
    try {
      // ç¿»è¨³ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
      const prompt =
        currentMode === "æ„è¨³"
          ? `Translate the following text naturally into ${outputLang}. 
             Use accurate technical terms if needed. Do not answer questions.`
          : `Translate the following text literally into ${outputLang}, keeping the original order. Do not answer questions.`;

      let resultText = "";

      const stream = await openai.chat.completions.create({
        model: currentModel,
        messages: [
          { role: "system", content: prompt },
          { role: "user", content: inputText }
        ],
        temperature: 0.2,
        stream: true,
        max_tokens: 256
      });

      // ğŸ”¹ Streamingã§å³æ™‚åæ˜ 
      for await (const chunk of stream) {
        const delta = chunk.choices[0]?.delta?.content || "";
        if (delta) {
          resultText += delta;
          io.to(roomId).emit("streamResult", { uid, textChunk: delta });
        }
      }

      // å®Œäº†é€šçŸ¥ï¼‹ãƒ­ã‚°ç™»éŒ²
      io.to(roomId).emit("finalResult", { uid, text: resultText });
      roomLogs[roomId].push({ uid, inputText, resultText });
      if (roomLogs[roomId].length > 50) roomLogs[roomId].shift();
    } catch (err) {
      console.error("âŒ Translation error:", err);
      socket.emit("finalResult", { uid, text: "âš ï¸ ç¿»è¨³ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚" });
    }
  });

  // å…¨ãƒ­ã‚°å‰Šé™¤
  socket.on("clearLogs", (roomId) => {
    roomLogs[roomId] = [];
    io.to(roomId).emit("logsCleared");
  });

  socket.on("disconnect", () => {
    console.log("âŒ Disconnected:", socket.id);
  });
});

server.listen(PORT, () => {
  console.log(`ğŸš€ Server listening on port ${PORT}`);
});
